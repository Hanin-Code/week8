{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIDHTRHu04ir"
      },
      "source": [
        "# Text Classification Exam\n",
        "\n",
        "Welcome to the Text Classification Practical Exam. In this exam, you will be tasked with building, training, and evaluating an NLP model to classify text data. You are provided with a labeled dataset containing both the text and its corresponding class labels.\n",
        "\n",
        "Your objective is to develop a model that accurately predicts the class of the given text. Make sure to follow best practices in data preprocessing, model selection, and evaluation to achieve optimal results.\n",
        "\n",
        "Good luck!\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqw2El5mMxsz"
      },
      "source": [
        "# Install and Import Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarabic"
      ],
      "metadata": {
        "id": "Ebc96GTZDCkv",
        "outputId": "1c829cb3-ab53-4665-c13a-d9a3808ce268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z6mRe6i5Wqqc",
        "outputId": "b6ebcad4-68e0-4f6a-9f1c-85a0fe28de42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import pyarabic.araby as araby\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Bidirectional, SimpleRNN, LSTM\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq5KJRZ5Ph0Z"
      },
      "source": [
        "# Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wmUcgV_x04it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffbe682-c5ee-4a13-e2a1-4b988b58dd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
            "Dataset URL: https://www.kaggle.com/datasets/khaledzsa/spam-messages\n",
            "License(s): unknown\n",
            "Downloading spam-messages.zip to /content\n",
            "  0% 0.00/213k [00:00<?, ?B/s]\n",
            "100% 213k/213k [00:00<00:00, 74.5MB/s]\n",
            "Archive:  spam-messages.zip\n",
            "  inflating: spam.csv                \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d khaledzsa/spam-messages\n",
        "!unzip spam-messages.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/spam.csv')"
      ],
      "metadata": {
        "id": "gh4WKDR-4_3N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVc0b_9fQGeH"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98DaVUvQsi8"
      },
      "source": [
        "Before diving into preprocessing and model building, it’s important to first explore the dataset to understand its structure, distribution, and key characteristics. This step will help you gain insights into the data and guide your decisions in subsequent steps. Here’s what to consider:\n",
        "\n",
        "1. **Inspect the Data**:\n",
        "   Start by looking at the first few rows of the dataset to get a sense of its structure. Check the columns, data types, and a few sample entries. This helps to ensure that the data is loaded correctly and gives you an initial overview of the content.\n",
        "\n",
        "2. **Check for Missing Values**:\n",
        "   Identify if there are any missing values in the dataset.\n",
        "\n",
        "3. **Distribution of Labels**:\n",
        "   Examine the distribution of the target labels (classes).\n",
        "\n",
        "4. **Text Data Characteristics (Bonus)**:\n",
        "   Analyze the length of the text data. It is useful to calculate the number of words or characters in each text sample to understand how long the texts are. This will help you set a suitable `max_length` for tokenization and padding later. You can plot a histogram of text lengths to visualize the distribution.\n",
        "\n",
        "5. **Common Words and Vocabulary (Bonus)**:\n",
        "   Explore the most frequent words in the text data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUFP1cOcDsa1",
        "outputId": "8d4112b7-66af-4535-95e6-cd3987a64422"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5572 non-null   object\n",
            " 1   label   5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFX0QGxIF-0n",
        "outputId": "c95644f5-ce17-4ff0-c1b6-23423ff3e824"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TXnFyT8EDvmK",
        "outputId": "2da3e235-db70-4224-d9d9-95b876c95099"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text label\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b066bb3f-0658-4ad9-bc0e-ef0575568d05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b066bb3f-0658-4ad9-bc0e-ef0575568d05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b066bb3f-0658-4ad9-bc0e-ef0575568d05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b066bb3f-0658-4ad9-bc0e-ef0575568d05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6fd2189-a88d-47ad-84f7-541ab4bcc64d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6fd2189-a88d-47ad-84f7-541ab4bcc64d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6fd2189-a88d-47ad-84f7-541ab4bcc64d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5389,\n        \"samples\": [\n          \"Last Chance! Claim ur \\u00e5\\u00a3150 worth of discount vouchers today! Text SHOP to 85023 now! SavaMob, offers mobile! T Cs SavaMob POBOX84, M263UZ. \\u00e5\\u00a33.00 Sub. 16 https://link2.com\",\n          \"Ok try to do week end course in coimbatore.\",\n          \"Haven't eaten all day. I'm sitting here staring at this juicy pizza and I can't eat it. These meds are ruining my life. https://link3.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aZgYQbZxWtAt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "7bcc4a70-5b21-4884-c8b3-486862a0e093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text label\n",
              "4703  Yar but they say got some error. https://link3...   ham\n",
              "927                 K:)i will give my kvb acc details:)   ham\n",
              "3618  8007 25p 4 Alfie Moon's Children in Need song ...  spam\n",
              "3714  I am late,so call you tomorrow morning.take ca...   ham\n",
              "2676  * Am on a train back from northampton so i'm a...   ham\n",
              "3331  Ok... The theory test? when are Ì_ going to bo...   ham\n",
              "3710  Sorry pa, i dont knw who ru pa? https://link1.com   ham\n",
              "4252  Juz now havent woke up so a bit blur blur... C...   ham\n",
              "1665  Dunno cos i was v late n when i reach they ins...   ham\n",
              "4600  FreeMsg: Txt: CALL to No: 86888 & claim your r...  spam"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc623927-d904-4ad5-b67f-139860461009\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4703</th>\n",
              "      <td>Yar but they say got some error. https://link3...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>K:)i will give my kvb acc details:)</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3618</th>\n",
              "      <td>8007 25p 4 Alfie Moon's Children in Need song ...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3714</th>\n",
              "      <td>I am late,so call you tomorrow morning.take ca...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2676</th>\n",
              "      <td>* Am on a train back from northampton so i'm a...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>Ok... The theory test? when are Ì_ going to bo...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3710</th>\n",
              "      <td>Sorry pa, i dont knw who ru pa? https://link1.com</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4252</th>\n",
              "      <td>Juz now havent woke up so a bit blur blur... C...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>Dunno cos i was v late n when i reach they ins...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>FreeMsg: Txt: CALL to No: 86888 &amp; claim your r...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc623927-d904-4ad5-b67f-139860461009')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc623927-d904-4ad5-b67f-139860461009 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc623927-d904-4ad5-b67f-139860461009');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a32ad1e6-d8c4-490c-9918-b97e27873740\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a32ad1e6-d8c4-490c-9918-b97e27873740')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a32ad1e6-d8c4-490c-9918-b97e27873740 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Dunno cos i was v late n when i reach they inside already... But we ate spageddies lor... It's e gals who r laughing at me lor...\",\n          \"K:)i will give my kvb acc details:)\",\n          \"Ok... The theory test? when are \\u00cc_ going to book? I think it's on 21 may. Coz thought wanna go out with jiayin. But she isnt free https://link3.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8GYmIUeEIWo",
        "outputId": "31120401-01d7-4f5e-a12c-9b326d9eec0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "ham     4825\n",
              "spam     747\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df['label'].value_counts()\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.bar(df2.index , df2.values )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "Ucqn6S5BEHle",
        "outputId": "b07c780a-3e1c-44b5-9897-a353e79ec00a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].str.len().max() #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_bs5jtkEwBv",
        "outputId": "03702b35-2c01-461b-cc56-b5f310afc136"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "910"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# explore common words & vocab\n",
        "from collections import Counter\n",
        "all_text =''.join(df['text'])\n",
        "words = all_text.split()\n",
        "word_counts = Counter(words)\n",
        "most_common_words = word_counts.most_common(10)\n",
        "print(most_common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu6NEdC4FELv",
        "outputId": "901229ad-ce8d-45b5-e6b5-ea7edce0cc10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('to', 2132), ('you', 1607), ('a', 1327), ('the', 1196), ('I', 1079), ('and', 857), ('in', 797), ('is', 778), ('i', 732), ('u', 688)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_oEu0TkSMEB"
      },
      "source": [
        "# Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSAFiozlRQHt"
      },
      "source": [
        "In this section, we will focus on cleaning and filtering the dataset, preparing it for the text classification task. We will implement the following steps:\n",
        "\n",
        "1. **Remove missing values**:  \n",
        "   First, we eliminate any rows with missing values to ensure the dataset is complete and consistent.\n",
        "\n",
        "2. **Filter by text length (Bonus)**:  \n",
        "   To maintain a uniform dataset, we will filter the text samples by a specified word count range. This ensures that the texts are neither too short to lack context nor too long to introduce unnecessary complexity.\n",
        "\n",
        "3. **English stopwords loading**:  \n",
        "   We load a list of English stopwords to filter out commonly used but contextually insignificant words. This is an important step for improving the performance of the model, as stopwords do not contribute valuable information.\n",
        "\n",
        "4. **Text cleaning**:  \n",
        "   We apply a series of text cleaning steps to standardize and simplify the text data. This involves:\n",
        "   \n",
        "   - **Removing links (URLs)**:  \n",
        "     Any URLs present in the text are removed as they are not meaningful for classification purposes.\n",
        "   \n",
        "   - **Removing special characters and punctuation**:  \n",
        "     This step removes any non-alphabetical characters, ensuring the text only contains meaningful words.\n",
        "   \n",
        "   - **Lowercasing**:  \n",
        "     All text is converted to lowercase for uniformity and to avoid case sensitivity issues.\n",
        "   \n",
        "   - **Removing English stopwords**:  \n",
        "     Words that are part of the stopwords list are removed, as they do not add value to the classification task.\n",
        "   \n",
        "   - **Stemming or Lemmatization**:  \n",
        "     Either stemming or lemmatization is applied to reduce words to their root or base form, ensuring consistency in word forms.\n",
        "\n",
        "5. **Final cleanup**:\n",
        "   Apply the cleanup function to the feature column.\n",
        "\n",
        "By following these steps, the text will be cleaned, filtered, and ready for tokenization!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mHEObOY_fHhq"
      },
      "outputs": [],
      "source": [
        "# Filter by text length\n",
        "df = df[df['text'].str.split().str.len().between(20, 250)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+','', text, flags=re.MULTILINE) # remove links\n",
        "\n",
        "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text) #remove special character\n",
        "\n",
        "    cleaned_text = araby.strip_tashkeel(cleaned_text) # remove taskkeel\n",
        "    cleaned_text = araby.strip_tatweel(cleaned_text) # remove tatweel\n",
        "    cleaned_text = araby.strip_lastharaka(cleaned_text) #remove last haraka\n",
        "\n",
        "    words = cleaned_text.split() # Tokenize the text\n",
        "\n",
        "    filtered_words = [token.word for token in doc if  not token.is_stop ]\n",
        "    return cleaned_text\n"
      ],
      "metadata": {
        "id": "34qXN1HWIX8F"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = clean_text(df['text'][1])\n",
        "\n",
        "print(f'Before: {df[\"text\"][1]}')\n",
        "print(f'After: {cleaned_text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "vY7KubdjLM-z",
        "outputId": "406cd2d1-7166-4ab5-b19d-2b760608235c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3e122ab8ed5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Before: {df[\"text\"][1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'After: {cleaned_text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# مالها دخل بالكود جالسه احاول I'm just trying ):\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"There is a pen on the table\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "filtered_words = [token.text for token in doc if not token.is_stop] #remove stop word\n",
        "clean_text = ' '.join(filtered_words)\n",
        "\n",
        "print(\"Original Text:\", text)\n",
        "print(\"Text after Stopword Removal:\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kju0mmzHgzM",
        "outputId": "917b778a-9141-4ab2-c7c3-542e84771f45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: There is a pen on the table\n",
            "Text after Stopword Removal: pen table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vme8eE8BQfsb",
        "outputId": "9adb3e56-e51f-4379-df72-9f46eb89380c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "word_tokens = word_tokenize(clean_text)\n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "\tif w not in stop_words:\n",
        "\t\tfiltered_sentence.append(w)\n",
        "\n",
        "print(word_tokens)\n",
        "print(filtered_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "KcWtIijuGPQy",
        "outputId": "a2ccbf53-c977-48c6-82f2-f44a58f42f5e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b18fd1353f7c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#with no lower case conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \"\"\"\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \"\"\"\n\u001b[0;32m-> 1341\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_last_whitespace_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \"\"\"\n\u001b[1;32m   1458\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mprevious_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mprevious_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;31m# Get the slice of the previous word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_stopwords= set(stopwords.words('arabic'))\n",
        "st = ISRIStemmer()\n",
        "def clean_text(text):\n",
        "    cleaned_text = re.sub(r'http\\S+|www\\S+|https\\S+','', text, flags=re.MULTILINE) # remove links\n",
        "\n",
        "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text) # remove special character & punctuations\n",
        "\n",
        "    cleaned_text = araby.strip_tashkeel(cleaned_text) #remove tashkeel\n",
        "    cleaned_text = araby.strip_tatweel(cleaned_text) # remove elongated letters\n",
        "    cleaned_text = araby.strip_lastharaka(cleaned_text) # remove last haraka\n",
        "\n",
        "    words = cleaned_text.split() # Tokenize the text\n",
        "\n",
        "    filtered_words = [word for word in words if word not in arabic_stopwords ]  # remove stopwords\n",
        "\n",
        "    # Apply stemming to the text\n",
        "    stemmed_words = ''.join(filtered_words)\n",
        "\n",
        "    # Apply norlize\n",
        "    cleaned_text = araby.normalize_hamza(stemmed_words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "cleaned_text = clean_text(df['text'][1])\n",
        "\n",
        "print(f'Before: {df[\"text\"][1]}')\n",
        "print(f'After: {cleaned_text}')"
      ],
      "metadata": {
        "id": "TcO45NO4GXuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF45GS_ZSEix"
      },
      "source": [
        "# Tokenization, Padding, and Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmsL3S-5SIbl"
      },
      "source": [
        "In this step, we will prepare the text data for input into a model by converting the text into numerical sequences, padding them to a uniform length, and splitting the dataset into training and testing sets. Here's an overview of the steps involved:\n",
        "\n",
        "1. **Tokenization**:\n",
        "   We use a tokenizer to convert the cleaned text into numerical sequences. You can use `Tokenizer` tokenizer from `tensorflow.keras.preprocessing.text` package or any other tokenizer you like.\n",
        "\n",
        "2. **Text to sequences**:\n",
        "   After fitting the tokenizer on the cleaned text, we transform each text into a sequence of numbers, where each number corresponds to a token (word) in the text.\n",
        "\n",
        "3. **Padding the sequences**:\n",
        "   Since different texts may vary in length, we pad the sequences to ensure they all have the same length.\n",
        "\n",
        "4. **Label encoding**:\n",
        "   The labels (target values) also need to be converted into numerical form if they are not encoded.\n",
        "\n",
        "5. **Train-test split**:\n",
        "   The dataset is divided into training and testing sets. We allocate 80% of the data for training the model and reserve 20% for testing its performance.\n",
        "   \n",
        "   - The **training data** consists of the padded sequences used to train the model.\n",
        "   - The **training labels** are the encoded labels corresponding to the training data.\n",
        "   - The **testing data** is used to assess the model’s performance after training.\n",
        "   - The **testing labels** are the encoded labels corresponding to the testing data.\n",
        "\n",
        "6. **Data shape confirmation**:\n",
        "   After splitting the data, we print the shape (dimensions) of both the training and testing sets to confirm that the data is properly divided and formatted.\n",
        "\n",
        "By the end of this step, the text data will be transformed into padded numerical sequences, the labels will be encoded, and the data will be split into training and testing sets for model development and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "z401Re0VfI1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "collapsed": true,
        "outputId": "f34bbb91-6626-49d5-a079-fbbb242708e2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tokenizer' object has no attribute 'fit_on_text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b3d1407d5f38>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msequnces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleaned_tect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'fit_on_text'"
          ]
        }
      ],
      "source": [
        "tokenize = Tokenizer()\n",
        "## خطوة الي فوق لسا ما انتهيت منها المفترض بعد الانتهاء احفظها باوبجكت وينحط هنا\n",
        "tokenize.fit_on_text(df['cleaned_text'])\n",
        "sequnces = tokenize.texts_to_sequences(df['cleaned_tect']) #Text to sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].str.len().max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "FnoxeHvSuKqi",
        "outputId": "b6eb0a5e-a191-46b9-ef32-ac56bfc43997"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-93bc7acfa7e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding the sequences\n",
        "max_length = df['text'].str.len().max()\n",
        "#\n",
        "padded_sequences = pad_sequences( sequences, maxlen = max_length, padding='post')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "collapsed": true,
        "id": "cN71UHm2ReGJ",
        "outputId": "29f5ec84-c3a6-4877-fed0-6e71256a787a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sequences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a6749b3ca1d1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Padding the sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpadded_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encodeing\n",
        "label_encoder = LabelEncoder()\n",
        "encoder_labels = label_encoder.fit_transform(['label'])"
      ],
      "metadata": {
        "id": "EEOhEMnTSUpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    padded_sequences,\n",
        "    encoder_labels,\n",
        "    test_size=0.2,\n",
        "    train_size=0.8\n",
        ")\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "aTh44sW9TNh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd5Ek4NLTgVN"
      },
      "source": [
        "# Building the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpLEoTaITEGx"
      },
      "source": [
        "In this step, you will design and build a NLP Classifier model to classify text data. Below is a breakdown of the key components you'll implement, but it's up to you to decide how to configure them based on your understanding and experimentation:\n",
        "\n",
        "1. **Model Type**:\n",
        "   You will use a Sequential model, which allows you to stack layers in a linear sequence.\n",
        "\n",
        "2. **Input Layer**:\n",
        "   Define the shape of the input data. Consider the dimensions of your padded sequences and set the input shape accordingly.\n",
        "\n",
        "3. **Embedding Layer**:\n",
        "   The embedding layer will convert input tokens (integers) into dense vector representations. You will need to determine the size of the input dimension (based on your vocabulary) and the output dimension (embedding size).\n",
        "\n",
        "4. **Bidirectional Simple RNN/LSTM Layers**:\n",
        "   You can add one or more recurrent layers. Consider using Bidirectional layers to capture contextual information from both directions (forward and backward). You can chose SimpleRNN/GRU/LSTM to perform this step.\n",
        "\n",
        "5. **Dense Layers**:\n",
        "   Add one or more fully connected (Dense) layers to process the output from the RNN/GRU/LSTM layers.\n",
        "\n",
        "6. **Output Layer**:\n",
        "   The output layer should match the type of classification task you're working on. Consider using appropriate activation function with appropriate number of units.\n",
        "\n",
        "7. **Model Summary**:\n",
        "   After defining your model architecture, print a summary to review the number of layers, types of layers, and total parameters.\n",
        "\n",
        "8. **Model Compilation**:\n",
        "   Finally, compile the model by selecting an optimizer, a loss function, and metrics."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(max_length,)),\n",
        "\n",
        "    Embedding(input_dim=len(tokenize.word_index) +1, output_dim=128, input_length = max_length),\n",
        "    Bidirectional(SimpleRNN(64, return_sequences = True)),\n",
        "    Bidirectional(SimpleRNN(30)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid') #for binary\n",
        "])\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "q-z3v_esVE4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57DXwqqQTloy"
      },
      "source": [
        "# Defining Batch Size, Creating Datasets, and Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEOvs_dETmQp"
      },
      "source": [
        "In this step, you will define the batch size, create TensorFlow Datasets for both training and testing, and train the model. The key elements to consider are outlined below, and it is up to you to choose the specific configurations based on your preferences and experimentation:\n",
        "\n",
        "1. **Batch Size**:\n",
        "   Select a batch size for training and testing. The batch size determines how many samples will be processed together in one forward and backward pass during training.\n",
        "\n",
        "2. **Creating Datasets**:\n",
        "   Use TensorFlow’s `Dataset.from_tensor_slices()` to create datasets from the training and testing data.\n",
        "\n",
        "3. **Batching the Datasets**:\n",
        "   Batch the datasets by grouping the data into batches of the specified size.\n",
        "\n",
        "4. **Training the Model**:\n",
        "   Train the model by fitting it on the training dataset for a specified number of epochs. You will also need to provide the validation data to monitor the model’s performance on unseen data during training.\n",
        "\n",
        "5. **Tracking Training History**:\n",
        "   During training, the model’s performance metrics (such as loss and accuracy) will be tracked over the epochs, and the results will be stored in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "\n",
        "train_dataset = tensorflow.data.Dataset.from_tensor_slices((train_data,train_labels))\n",
        "test_dataset = tensorflow.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "\n",
        "train_dataset =train_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "history = model.fit(train_dataset , epochs=5, validation_data = test_dataset)"
      ],
      "metadata": {
        "id": "OWfIM8mAVer3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6unhJgFfQbM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmoJfr3nfP-n"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gb8G9XiT-ec"
      },
      "source": [
        "Once the model is trained, the next step is to evaluate its performance on the testing dataset.\n",
        "\n",
        "1. **Evaluate the Model**:\n",
        "   You will use the `evaluate()` method to assess the model’s performance on the test dataset.\n",
        "\n",
        "2. **Testing Dataset**:\n",
        "   Ensure that the testing dataset is properly prepared and batched, just like the training dataset.\n",
        "\n",
        "4. **Loss Curve**:\n",
        "   A loss curve plots the loss values for both the training and validation datasets over the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdECXvQGUQae"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)\n",
        "print(f\"Accuracy: {results[1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifx5RFxnUQqc"
      },
      "source": [
        "# Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVh0WCBoUSlP"
      },
      "source": [
        "In this step, you will use the trained model to make predictions on new, unseen data (inference). Here’s an outline of the key points:\n",
        "\n",
        "1. **Create Test Sample**:\n",
        "   Create a string to test your modelm the goal here is to give the model Before making predictions, ensure that the new data is preprocessed in the same way as the training data. This includes tokenization, padding, and any other transformations you applied during the data preprocessing step. The data can be single text to see the result of the prediction.\n",
        "\n",
        "2. **Model Prediction**:\n",
        "   Use the `predict()` method to feed new samples into the trained model and obtain predictions. The model will output probabilities or predicted class labels based on the type of classification task (binary or multi-class).\n",
        "\n",
        "3. **Interpreting Predictions**:\n",
        "   The model will return probabilities for each class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the data\n",
        "sample_text = [\"التجربه سيئة\"]\n",
        "sample_sequences = tokenizer.texts_to_sequences([clean_text[0]])\n",
        "padded_sample_sequence =pad_sequences(sample_sequences, maxlen=max_length, paddings='post')\n",
        "\n",
        "\n",
        "#model prediction\n",
        "predicated_label = model.predict(padded_sample_sequence)\n",
        "print(\"pridiction Label:\",label_encoder.inverse_transform([predicated_label.argmax()]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "3X0DoQSuc9dH",
        "outputId": "9c1a5871-b1ee-4f59-9efb-cd407784544c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-17d2968c6ea8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# prepare the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"التجربه سيئة\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpadded_sample_sequence\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtdtk4_d04iw"
      },
      "source": [
        "# Notebook Question:\n",
        "- How did you handle text preprocessing? Why did you choose this approach?\n",
        "\n",
        "- Why did you choose this model design?\n",
        "\n",
        "- Why did you pick this number of layers or units for the model?\n",
        "\n",
        "- Why did you select these evaluation methods?\n",
        "\n",
        "- Does your model show signs of overfitting or underfitting? How do you know?\n",
        "\n",
        "- What changes could you make to improve the model and fix overfitting or underfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6-3M7bY04iw"
      },
      "source": [
        "Answer Here:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data at first glance does not contain missing value and the binary contains ham & spam\n",
        "\n",
        "This is one of the reasons that made me choose sigmoid when building the model\n",
        "\n",
        "the data is unbalanced as ham = 4825, spam = 747\n",
        "\n",
        "Data is biased towards ham"
      ],
      "metadata": {
        "id": "MbPsbVmFaeDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the max length was 910 which is too long and for this reason  i filter by text length between [20, 250]"
      ],
      "metadata": {
        "id": "AODCmlmCbChn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I could not complete the solution because i hung up in cleaning the text):\n",
        "but i write the codes of the other step, but I did not run because I did not finish the step in the first place"
      ],
      "metadata": {
        "id": "xRPmA0agcGNC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}